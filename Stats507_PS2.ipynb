{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "from collections import defaultdict\n",
    "from timeit import Timer\n",
    "import time\n",
    "from IPython.core.display import HTML,display\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anuraag Ramesh**  \n",
    "1st October"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0 - Code Review Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]  \n",
    "op = []  \n",
    "for m in range(len(sample_list)):  \n",
    "    li = [sample_list[m]]  \n",
    "        for n in range(len(sample_list)):  \n",
    "            if (sample_list[m][0] == sample_list[n][0] and  \n",
    "                    sample_list[m][3] != sample_list[n][3]):  \n",
    "                li.append(sample_list[n])  \n",
    "        op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])  \n",
    "res = list(set(op))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet prints out the largest tuple with the same value at the first index.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Code Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please take care of the indentation in a python code, after for and while loops\n",
    "    - There is an indentation error in the code above \n",
    "    - Line 5: is unnecessarily indented\n",
    "    \n",
    "    \n",
    "- Pay attention to the list ranges while indexing\n",
    "    - There is an error here as the sample_list is indexed to 3, which gives an out of range error  \n",
    "    \n",
    "    \n",
    "- The code is not semantically correct, as converting a set to the list does not lead to the same maintained order\n",
    "\n",
    "\n",
    "- Use indexes only when necessary\n",
    "    - Here we can use values directly instead of indices after the for loop\n",
    "    \n",
    "    \n",
    "- 'nitpicks' Use more meaningful names as variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - List of Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tuples(n, k=3, low=5, high=15):\n",
    "    \"\"\"\n",
    "    Create a list of n- tuples with with size k\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "    Specifies the number of tuples\n",
    "    k : int\n",
    "    Specifies the size of each tuple\n",
    "    low : int\n",
    "    Specifies the lower range to pick the numbers \n",
    "    high : int\n",
    "    Specifies the range range to pick the numbers \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tup_list: list\n",
    "    Printing out a list of n-tuples\n",
    "    \"\"\"\n",
    "    tup_list = []\n",
    "    np.random.seed(1234)\n",
    "    for i in range(n):\n",
    "        tup = tuple([val \n",
    "                     for val in \n",
    "                     np.random.randint(low, high, k)])\n",
    "        tup_list.append(tup)\n",
    "    return tup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_tuples(4):\n",
    "    assert isinstance(i, tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Refactor the Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_snip(sample_list, a=0, b=2):\n",
    "    \"\"\"\n",
    "    Defining a function for the above code snippet\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list : list\n",
    "    Specifies the list of tuples\n",
    "    a : int\n",
    "    Parameterizes the lower index\n",
    "    b : int\n",
    "    Parameterizes the upper index \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res: list\n",
    "    \"\"\"\n",
    "    if(b > len(sample_list[0]) - 1):\n",
    "        b = len(sample_list[0]) - 1\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][a] == sample_list[n][a] \n",
    "                and sample_list[m][b] != sample_list[n][b]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key = lambda dd: dd[b], reverse = True)[0])\n",
    "    res = list(set(op))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 2), (1, 9, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(func_snip(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_imp(sample_list, a=0, b=2):\n",
    "    \"\"\"\n",
    "    Defining a function for sorting based on 'a' value of tuple\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list : list\n",
    "    Specifies the list of tuples\n",
    "    a : int\n",
    "    Parameterizes the lower index\n",
    "    b : int\n",
    "    Parameterizes the upper index \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res: list\n",
    "    Outputs the list of highest tuple with same first value\n",
    "    \"\"\"\n",
    "    if(b > len(sample_list[0]) - 1):\n",
    "        b=len(sample_list[0]) - 1\n",
    "    # Improvements based on code review\n",
    "    op = []\n",
    "    # Using values instead of indexes\n",
    "    for m in sample_list:\n",
    "        li = [m]\n",
    "        for n in sample_list:\n",
    "            if (m[a] == n[a] and m[b] != n[b]):\n",
    "                li.append(n)\n",
    "        op.append(sorted(li, key = lambda x: x[b], reverse = True)[0])\n",
    "    # Using sorted to convert the set to a list\n",
    "    res = sorted(set(op))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 2), (1, 9, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(func_imp(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dict(sample_list, a=0, b=2):\n",
    "    \"\"\"\n",
    "    Defining a function for the above code snippet\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list : list\n",
    "    Specifies the list of tuples\n",
    "    a : int\n",
    "    Parameterizes the lower index\n",
    "    b : int\n",
    "    Parameterizes the upper index \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res: list\n",
    "    Outputs the list highest tuple for unique first value of tuple\n",
    "    \"\"\"\n",
    "    if(len(sample_list[0])-1):\n",
    "        b=len(sample_list[0])-1\n",
    "    op = defaultdict(list)\n",
    "    # For loop to put values in the defaultdict\n",
    "    for m in sample_list:\n",
    "        op[m[a]].append(m)\n",
    "    \n",
    "    res = []\n",
    "    for k, v in op.items():\n",
    "        # Sorting the list for each key\n",
    "        res.append(sorted(v, key = lambda x: x[b], reverse = True)[0])\n",
    "    return sorted(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 2), (1, 9, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(func_dict(sample_list, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Monte Carlo Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "def monte_carlo(min_var, max_var):\n",
    "    \"\"\"\n",
    "    Give a random value using the uniform distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_var : int\n",
    "    Lower range of the variable\n",
    "    max_var:\n",
    "    Higher range of the variable\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    min_var+round(val) : float\n",
    "    Gives the psuedo random of a variable(from the range)\n",
    "    \"\"\"\n",
    "    range_var = max_var-min_var\n",
    "    # Using a uniform distribution to produce a pseudo random value\n",
    "    random_val = np.random.uniform(0, 1)\n",
    "    val = range_var * random_val\n",
    "    return(min_var + round(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo(1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a monte carlo study with each variable being randomly selected using a *Uniform Distribution* from a range of values.  \n",
    "The following variables are being randonly selected:\n",
    "- n : number of tuples\n",
    "- k : size of each tuple\n",
    "- low : lower value of each number in tuple\n",
    "- high: lower value of each number in tuple\n",
    "- a: The lower index to compare\n",
    "- b: The higher index to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_study(func, var_list, n_samples=50):\n",
    "    \"\"\"\n",
    "    Performing a monte carlo study for n_samples\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : function\n",
    "    Specifies the function that needs to be tested\n",
    "    list_var:\n",
    "    A list of variable taht is part of simulation\n",
    "    n_samples:\n",
    "    Number of times the function is tested\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    final_comp_time : float\n",
    "    Gives the average value of the comp_time for the function\n",
    "    \"\"\"\n",
    "    sum_time = 0\n",
    "    #Setting default values for the variables\n",
    "    n = 6\n",
    "    k = 3\n",
    "    low = 0 \n",
    "    high = 15\n",
    "    a = 0\n",
    "    b = k - 1\n",
    "    for i in range(n_samples):\n",
    "        # Simulating the number of tuples - range(2,30)\n",
    "        if('n' in var_list):\n",
    "            n = monte_carlo(2, 30)\n",
    "        # Simulating the size of the tuples - range(3,20)\n",
    "        if('k' in var_list):\n",
    "            k = monte_carlo(3, 20)\n",
    "        # Simulating the value of high - range(0,24)\n",
    "        if('low' in var_list):\n",
    "            low = monte_carlo(0, 24)\n",
    "        # Simulating the value of low - range(10,30)\n",
    "        if('high' in var_list):\n",
    "            high = monte_carlo(10, 30)\n",
    "        # Simulating the value of a - range(0,20)\n",
    "        if('a' in var_list):\n",
    "            a = monte_carlo(0, 20)\n",
    "        # Simulating the value of b - range(2,20)\n",
    "        if('b' in var_list):\n",
    "            b = monte_carlo(2, 20)\n",
    "        if(high > low and k > a and k >= b and b > a):\n",
    "            # Now calculate the time\n",
    "            li = list_tuples(n, k, low, high)\n",
    "            start = time.time()\n",
    "            func(li, a, b)\n",
    "            end = time.time()\n",
    "            comp_time = end - start\n",
    "            sum_time = sum_time + comp_time\n",
    "        else:\n",
    "            continue\n",
    "    final_comp_time = round(sum_time / n_samples, ndigits = 7)\n",
    "    return(final_comp_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the monte carlo study for the computation times for each of the functions (func_snip, func_imp, func_dict).  \n",
    "\n",
    "We can define a list and add it to the function to select the number of variables that are being randomized to generate an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "comp_list = []\n",
    "var_lists = []\n",
    "var_list = [['n'], ['n', 'k', 'low'], ['n', 'k', 'low', 'high']]\n",
    "func_name = ['Snippet Func', 'Improve Func', 'Dictionary Func']*3\n",
    "func = [func_snip, func_imp, func_dict]\n",
    "functions = [func_snip, func_imp, func_dict]\n",
    "\n",
    "for i in var_list:\n",
    "    for j in func:\n",
    "        comp_time = monte_study(j, i , 1000)\n",
    "        comp_list.append(comp_time)\n",
    "        var_lists.append(i)\n",
    "\n",
    "monte_sim1 = {'sim variables':var_lists, 'function names':func_name,\n",
    "              'computation time':comp_list}\n",
    "        \n",
    "\n",
    "# DataFrame\n",
    "monte_sim = pd.DataFrame(monte_sim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim variables</th>\n",
       "      <th>function names</th>\n",
       "      <th>computation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[n]</td>\n",
       "      <td>Snippet Func</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[n]</td>\n",
       "      <td>Improve Func</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[n]</td>\n",
       "      <td>Dictionary Func</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[n, k, low]</td>\n",
       "      <td>Snippet Func</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[n, k, low]</td>\n",
       "      <td>Improve Func</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[n, k, low]</td>\n",
       "      <td>Dictionary Func</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[n, k, low, high]</td>\n",
       "      <td>Snippet Func</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[n, k, low, high]</td>\n",
       "      <td>Improve Func</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[n, k, low, high]</td>\n",
       "      <td>Dictionary Func</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(monte_sim.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can clearly see that in all the different versions of the monte carlo study that the `#3rd Version: defaultdict` is the one that takes the least amount of time to run.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - NHANES Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Appending Nhanes Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four cohorts are:\n",
    "- **Baby Boomers**: Born 1946 - 1964\n",
    "- **Generation X**: Born 1965-1976\n",
    "- **Millenials or Generation Y**: Born 1977-1995\n",
    "- **Gen Z**: Born 1996 and after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meaning of variables:**  \n",
    "\n",
    "**SEQN**: Respondent sequence number  \n",
    "**RIDAGEYR**: Age in years of the participant at the time of screening  \n",
    "**RIDRETH3**: Recode of reported race   \n",
    "**DMDEDUC2**: Education  \n",
    "**DMDMARTL**: Marital Status  \n",
    "**RIDSTATR**: Interview and examination status of the participant  \n",
    "**SDMVPSU**: Masked variance unit pseudo-PSU variable for variance estimation  \n",
    "**SDMVSTRA**: Masked variance unit pseudo-stratum variable for variance estimation  \n",
    "**WTMEC2YR**: Full sample 2 year MEC exam weight  \n",
    "**WTINT2YR**: Full sample 2 year interview weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the SAS files to combine \n",
    "nhanes = ['DEMO_G.XPT',\n",
    "          'DEMO_H.XPT',\n",
    "          'DEMO_I.XPT',\n",
    "          'DEMO_J.XPT']\n",
    "\n",
    "oral_dent = ['OHXDEN_G.XPT',\n",
    "             'OHXDEN_H.XPT',\n",
    "             'OHXDEN_I.XPT',\n",
    "             'OHXDEN_J.XPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_def(demo_dent):\n",
    "    \"\"\"\n",
    "    Defining the year based on database\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_dent : list\n",
    "    Gives the locations of the demographic data SAS files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    year: int\n",
    "    Gives out the year of the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    if('G' in demo_dent):\n",
    "        year = 2011\n",
    "    elif('H' in demo_dent):\n",
    "        year = 2013\n",
    "    elif('I' in demo_dent):\n",
    "        year = 2015\n",
    "    elif('J' in demo_dent):\n",
    "        year = 2017\n",
    "    return year  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohort_def(age,data):\n",
    "    \"\"\"\n",
    "    Defined to cohort based on age \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    age : The RIDAGEYR variables\n",
    "    The age variables for unique SEQN\n",
    "    \n",
    "    demo_dent: list\n",
    "    Gives the locations of the demographic data SAS files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    check: string\n",
    "    Returns the cohort based on year\n",
    "    \"\"\"\n",
    "    \n",
    "    year=year_def(data)\n",
    "    if(age <= (year - 1996)):\n",
    "        return \"Gen Z\"\n",
    "    elif(age <= (year - 1977) and age > (year - 1995)):\n",
    "        return \"Gen Y\"\n",
    "    elif(age <= (year - 1965) and age > (year - 1976)):\n",
    "        return \"Gen X\"\n",
    "    else:\n",
    "        return \"Baby Boomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries fo the categorical variables for Demographic dataset\n",
    "ridreth3 = {1 : 'mexican', 2 : 'other hispanic', \n",
    "            3 : 'non-hispanic White', 4 : 'non-hispanic black',\n",
    "            6 : 'non-hispanic Asian', 7 : 'other race'}\n",
    "\n",
    "ridstatr = {1 : 'interviewed only', 2: 'both'}\n",
    "\n",
    "dmdecu2 ={1 : 'less than 9th', 2 : '9 to 11', 3:'hs graduate',\n",
    "          4 : 'college', 5 : 'college graduate', 7 : 'refused',\n",
    "          9 : 'dont know'}\n",
    " \n",
    "dmdmartl = {1 : 'married', 2 : 'widowed', 3 : 'divorced',\n",
    "            4 : 'separated', 5 : 'never married',\n",
    "            6: 'living with partner', 77 : 'refused',\n",
    "            99 : 'dont know'}\n",
    "riagendr = {1 : 'male', 2: 'female'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining NHANES Demographic data from different years\n",
    "def initial_data(nhanes_link):\n",
    "    \"\"\"\n",
    "    Cleaning and Combining NHANES Demographic DataFrame \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nhanes_link : list\n",
    "    Specifies the location for the demographic dataset(different years)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nhanes_data: Pandas Dataframe\n",
    "    Gives the combined Dataframe as output\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nhanes_data = pd.DataFrame()\n",
    "    for i in range(len(nhanes_link)):\n",
    "        data = pd.read_sas(nhanes_link[i])\n",
    "        data = data.loc[:,['SEQN', 'RIDAGEYR', 'RIAGENDR','RIDRETH3',\n",
    "          'DMDEDUC2', 'DMDMARTL', 'RIDSTATR',\n",
    "          'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "        #Adding the cohort column\n",
    "        data['cohort'] = data['RIDAGEYR'].apply(cohort_def, data=nhanes_link[i])\n",
    "        nhanes_data = nhanes_data.append(data)\n",
    "    \n",
    "    # Correcting the type of the different columns in the table\n",
    "    for i in nhanes_data.columns:\n",
    "        if(i == 'RIDAGEYR' or i == 'SDMVPSU' or i == 'SDMVSTRA'):\n",
    "            nhanes_data[i] = nhanes_data[i].astype('int64')\n",
    "        elif(i == 'RIDRETH3'):\n",
    "            nhanes_data[i] = pd.Categorical(nhanes_data[i].replace(ridreth3))\n",
    "        elif(i == 'RIAGENDR'):\n",
    "            nhanes_data[i] = pd.Categorical(nhanes_data[i].replace(riagendr))\n",
    "        elif(i == 'RIDSTATR'):\n",
    "            nhanes_data[i] = pd.Categorical(nhanes_data[i].replace(ridstatr))\n",
    "        elif(i == 'DMDEDUC2'):\n",
    "            nhanes_data[i] = pd.Categorical(nhanes_data[i].replace(dmdecu2))\n",
    "        elif(i == 'DMDMARTL'):\n",
    "            nhanes_data[i] = pd.Categorical(nhanes_data[i].replace(dmdmartl))\n",
    "        elif(i == 'cohort'):\n",
    "            nhanes_data[i] = nhanes_data[i].astype('category')\n",
    "        elif(i == 'WTMEC2YR' or i == 'WTINT2YR'):\n",
    "            nhanes_data[i] = nhanes_data[i].astype('float64')\n",
    "            \n",
    "    nhanes_data = nhanes_data.rename(columns=\n",
    "                                     {'RIDAGEYR':'age', \n",
    "                                      'RIDRETH3':'race',\n",
    "                                      'RIAGENDR': 'gender',\n",
    "                                      'DMDEDUC2':'education_level',\n",
    "                                      'DMDMARTL':'marital', \n",
    "                                      'RIDSTATR':'interview_status',\n",
    "                                      'SDMVPSU':'psuedo_PSU_var', \n",
    "                                      'SDMVSTRA':'psuedo_stratum_var', \n",
    "                                      'WTMEC2YR':'sample_weight_MEC', \n",
    "                                      'WTINT2YR':'sample_weight_int'})\n",
    "        \n",
    "    # Tidying and making the dataset clearer to read\n",
    "    nhanes_data = nhanes_data.set_index('SEQN')\n",
    "    return nhanes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhanes_data = initial_data(nhanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                      int64\n",
      "gender                category\n",
      "race                  category\n",
      "education_level       category\n",
      "marital               category\n",
      "interview_status      category\n",
      "psuedo_PSU_var           int64\n",
      "psuedo_stratum_var       int64\n",
      "sample_weight_MEC      float64\n",
      "sample_weight_int      float64\n",
      "cohort                category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(nhanes_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the nhanes_data to 'parquet' format\n",
    "nhanes_data.to_parquet('Nhanes Data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Appending Oral and Dentition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meaning of variables:**  \n",
    "\n",
    "**SEQN**: Respondent sequence number  \n",
    "**OHDDESTS**: Dentition Status  \n",
    "**Tooth counts (OHXxxTC)**: The Tooth Counts for each tooth (1-32)  \n",
    "**Coronal cavities (OHXxxCTC)**:The Cavity Counts for each tooth (1-31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuraagramesh/opt/miniconda3/envs/stats507/lib/python3.9/site-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "# Taking out the columns for slicing\n",
    "oral_rows = []\n",
    "data = pd.read_sas(oral_dent[0])\n",
    "for i in data.columns[0:64]:\n",
    "    if(i == 'OHXIMP' or i == 'OHDEXSTS'):\n",
    "        pass\n",
    "    else:\n",
    "        oral_rows.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries fo the categorical variables for Demographic dataset\n",
    "tc = {1 : 'primary tooth',\n",
    "      2 : 'permanent tooth',\n",
    "      3 : 'dental implant',\n",
    "      4 : 'not present',\n",
    "      5 : 'root',\n",
    "      9 : 'could not assess'}\n",
    "\n",
    "# r = restorative\n",
    "ctc = {'A' : 'restored primary tooth',\n",
    "       'D' : 'sound primary tooth',\n",
    "       'E' : 'missing - dental disease',\n",
    "       'F' : 'restored permanent tooth',\n",
    "       'J' : 'ppermanent root tip',\n",
    "       'K' : 'primary tooth - surface condition',\n",
    "       'M' : 'missing - other causes',\n",
    "       'P' : 'disease - r',\n",
    "       'Q' : 'other causes - r',\n",
    "       'R' : 'other causes - fr',\n",
    "       'S' : 'sound permanent tooth',\n",
    "       'T' : 'permanent root - r',\n",
    "       'U' : 'unerupted',\n",
    "       'X' : 'other causes - f',\n",
    "       'Y' : 'not assessed',\n",
    "       'Z' : 'permanent tooth - surface condition'}\n",
    "\n",
    "oddests={1 : 'complete',\n",
    "         2 : 'partial',\n",
    "         3 : 'not done'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Oral and Dentition data from different years\n",
    "def initial_data_oral(oral_link):\n",
    "    \"\"\"\n",
    "    Cleaning and Combining NHANES Oral and Dentition DataFrame \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    oral_link : list\n",
    "    Specifies the location for the nhanes dataset(Different years)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    oral_data: Pandas Dataframe\n",
    "    Gives the combined Dataframe as output\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    oral_data = pd.DataFrame()\n",
    "    for i in range(len(oral_link)):\n",
    "        data = pd.read_sas(oral_link[i])\n",
    "        data = data.loc[:, oral_rows]\n",
    "        oral_data = oral_data.append(data)\n",
    "    # Tidying and making the dataset clearer to read\n",
    "    # Correcting the type of the different columns in the table\n",
    "    for i in oral_rows:\n",
    "        if('CTC' in i):\n",
    "            oral_data[i] = oral_data[i].str.decode('utf-8') \n",
    "            oral_data[i] = pd.Categorical(oral_data[i].replace(ctc))\n",
    "            oral_data = oral_data.rename(columns={i:'coronial_' + i[3:5]})\n",
    "        elif('TC' in i):\n",
    "            oral_data[i] = pd.Categorical(oral_data[i].replace(tc))\n",
    "            oral_data = oral_data.rename(columns={i:'tooth_count_' + i[3:5]})\n",
    "        elif(i == 'OHDDESTS'):\n",
    "            oral_data[i] = pd.Categorical(oral_data[i].replace(oddests))\n",
    "            oral_data = oral_data.rename(columns={i:'dentition_status'})\n",
    "    oral_data = oral_data.set_index('SEQN')\n",
    "    return oral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_data = initial_data_oral(oral_dent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dentition_status    category\n",
      "tooth_count_01      category\n",
      "tooth_count_02      category\n",
      "tooth_count_03      category\n",
      "tooth_count_04      category\n",
      "                      ...   \n",
      "coronial_27         category\n",
      "coronial_28         category\n",
      "coronial_29         category\n",
      "coronial_30         category\n",
      "coronial_31         category\n",
      "Length: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(oral_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data to 'parquet' format\n",
    "oral_data.to_parquet('Oral Data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the datasets are saved in **parquet** format:  \n",
    "- Nhanes Data: 'Nhanes Data.gzip'\n",
    "- Oral Data: 'Oral Data.gzip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in NHANES data: 39156\n"
     ]
    }
   ],
   "source": [
    "# Read NHANES data from parquet\n",
    "nhanes_data1 = pd.read_parquet('Nhanes Data.parquet')\n",
    "# Length of Nhanes dataset\n",
    "print('Number of cases in NHANES data:', len(nhanes_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in NHANES data: 35909\n"
     ]
    }
   ],
   "source": [
    "# Read Oral Dentition data from parquet\n",
    "oral_data1 = pd.read_parquet('Oral Data.parquet')\n",
    "# Length of Oral Dentition dataset\n",
    "print('Number of cases in NHANES data:', len(oral_data1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b572f3e1c5e7cb8e35e8bb406beefaa53cf2ea2948b05e33f6712385e1e50ef9"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
